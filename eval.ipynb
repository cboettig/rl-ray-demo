{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': {'use_lstm': True},\n",
       " 'framework': 'torch',\n",
       " 'num_gpus': 1,\n",
       " 'num_workers': 4,\n",
       " 'env': 'gym_fishing.envs.FishingCtsEnv'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cloudpickle\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.rllib import agents\n",
    "import torch\n",
    "from ray.tune.registry import get_trainable_cls\n",
    "\n",
    "checkpoint = \"saved_checkpoint/checkpoint/checkpoint\"\n",
    "run = \"PPO\"\n",
    "env = \"gym_fishing.envs.FishingCtsEnv\"\n",
    "\n",
    "\n",
    "# Based on rllib evaluate,\n",
    "# https://github.com/ray-project/ray/blob/master/rllib/evaluate.py\n",
    "config_dir = os.path.dirname(checkpoint)\n",
    "config_path = os.path.join(config_dir, \"../params.pkl\")\n",
    "config_path\n",
    "with open(config_path, \"rb\") as f:\n",
    "    config = cloudpickle.load(f)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-06 04:50:48,075\tWARNING deprecation.py:45 -- DeprecationWarning: `simple_optimizer` has been deprecated. This will raise an error in the future!\n",
      "2022-03-06 04:50:48,210\tINFO trainable.py:472 -- Restored on 172.18.0.8 from checkpoint: saved_checkpoint/checkpoint/checkpoint\n",
      "2022-03-06 04:50:48,211\tINFO trainable.py:480 -- Current state after restoring: {'_iteration': 250, '_timesteps_total': 1000000, '_time_total': 2036.3581442832947, '_episodes_total': 19192}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=222871)\u001b[0m 2022-03-06 04:50:50,673\tWARNING deprecation.py:45 -- DeprecationWarning: `rllib.env.remote_vector_env.RemoteVectorEnv` has been deprecated. Use `ray.rllib.env.remote_base_env.RemoteBaseEnv` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=222875)\u001b[0m 2022-03-06 04:50:50,701\tWARNING deprecation.py:45 -- DeprecationWarning: `rllib.env.remote_vector_env.RemoteVectorEnv` has been deprecated. Use `ray.rllib.env.remote_base_env.RemoteBaseEnv` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=222878)\u001b[0m 2022-03-06 04:50:50,776\tWARNING deprecation.py:45 -- DeprecationWarning: `rllib.env.remote_vector_env.RemoteVectorEnv` has been deprecated. Use `ray.rllib.env.remote_base_env.RemoteBaseEnv` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=222872)\u001b[0m 2022-03-06 04:50:50,807\tWARNING deprecation.py:45 -- DeprecationWarning: `rllib.env.remote_vector_env.RemoteVectorEnv` has been deprecated. Use `ray.rllib.env.remote_base_env.RemoteBaseEnv` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=222866)\u001b[0m 2022-03-06 04:50:50,824\tWARNING deprecation.py:45 -- DeprecationWarning: `rllib.env.remote_vector_env.RemoteVectorEnv` has been deprecated. Use `ray.rllib.env.remote_base_env.RemoteBaseEnv` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=222864)\u001b[0m 2022-03-06 04:50:50,906\tWARNING deprecation.py:45 -- DeprecationWarning: `rllib.env.remote_vector_env.RemoteVectorEnv` has been deprecated. Use `ray.rllib.env.remote_base_env.RemoteBaseEnv` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=222881)\u001b[0m 2022-03-06 04:50:50,893\tWARNING deprecation.py:45 -- DeprecationWarning: `rllib.env.remote_vector_env.RemoteVectorEnv` has been deprecated. Use `ray.rllib.env.remote_base_env.RemoteBaseEnv` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=222882)\u001b[0m 2022-03-06 04:50:50,850\tWARNING deprecation.py:45 -- DeprecationWarning: `rllib.env.remote_vector_env.RemoteVectorEnv` has been deprecated. Use `ray.rllib.env.remote_base_env.RemoteBaseEnv` instead. This will raise an error in the future!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Based on rllib evaluate,\n",
    "# https://github.com/ray-project/ray/blob/master/rllib/evaluate.py\n",
    "# Make sure worker 0 has an Env.\n",
    "config[\"create_env_on_driver\"] = True\n",
    "# Make sure we have evaluation workers.\n",
    "if not config.get(\"evaluation_num_workers\"):\n",
    "    config[\"evaluation_num_workers\"] = config.get(\"num_workers\", 0)\n",
    "if not config.get(\"evaluation_duration\"):\n",
    "    config[\"evaluation_duration\"] = 1\n",
    "# Hard-override this as it raises a warning by Trainer otherwise.\n",
    "# Makes no sense anyways, to have it set to None as we don't call\n",
    "# `Trainer.train()` here.\n",
    "config[\"evaluation_interval\"] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the Trainer from config.\n",
    "cls = get_trainable_cls(run)\n",
    "agent = cls(env=env, config=config)\n",
    "\n",
    "agent.restore(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'evaluation': {'episode_reward_max': 6.638855040073395,\n",
       "  'episode_reward_min': 6.638855040073395,\n",
       "  'episode_reward_mean': 6.638855040073395,\n",
       "  'episode_len_mean': 101.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 1,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [6.638855040073395],\n",
       "   'episode_lengths': [101]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.06185559665455538,\n",
       "   'mean_inference_ms': 0.6857572817334943,\n",
       "   'mean_action_processing_ms': 0.05300372254614737,\n",
       "   'mean_env_wait_ms': 0.04398355297013826,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'timesteps_this_iter': 0}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in an ExperimentAnalysis from a json state file\n",
    "#results_path = \"~/ray_results/ARS/\"\n",
    "results_path = \"~/ray_results/fishing-ppo/\"\n",
    "\n",
    "analysis = tune.ExperimentAnalysis(experiment_checkpoint_path=results_path)\n",
    "#best_trial = analysis.get_best_trial(metric=\"episode_reward_mean\", mode=\"max\")\n",
    "best_trial = \"PPO_gym_fishing.envs.FishingCtsEnv_deefe_00000\"\n",
    "#best_checkpoint = analysis.get_best_checkpoint(trial=best_trial, metric=\"episode_reward_mean\", mode=\"max\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find best trial. Did you pass the correct `metric` parameter?\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'last_result'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/cboettig/cboettig/rl-ray-demo/eval.ipynb Cell 3'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Brstudio.thelio/home/cboettig/cboettig/rl-ray-demo/eval.ipynb#ch0000005vscode-remote?line=0'>1</a>\u001b[0m config \u001b[39m=\u001b[39m analysis\u001b[39m.\u001b[39;49mget_best_trial(metric\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mepisode_reward_mean\u001b[39;49m\u001b[39m\"\u001b[39;49m, mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmax\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mlast_result[\u001b[39m\"\u001b[39m\u001b[39mconfig\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brstudio.thelio/home/cboettig/cboettig/rl-ray-demo/eval.ipynb#ch0000005vscode-remote?line=1'>2</a>\u001b[0m \u001b[39m#analysis.get_best_trial(metric=\"episode_reward_mean\", mode=\"max\").last_result\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brstudio.thelio/home/cboettig/cboettig/rl-ray-demo/eval.ipynb#ch0000005vscode-remote?line=2'>3</a>\u001b[0m config\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'last_result'"
     ]
    }
   ],
   "source": [
    "\n",
    "#config = analysis.get_best_trial(metric=\"episode_reward_mean\", mode=\"max\").last_result[\"config\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the hyper-parameter config\n",
    "config = analysis.get_best_trial(metric=\"episode_reward_mean\", mode=\"max\").last_result[\"config\"]\n",
    "config.pop(\"in_evaluation\", None)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
