{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install torch gym_conservation \"ray[rllib, tune]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import gym\n",
    "import gym_conservation\n",
    "import gym_fishing\n",
    "from ray import tune\n",
    "from ray.rllib import agents\n",
    "from ray.rllib.agents import ppo, impala\n",
    "torch.cuda.device_count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom environment creator utility\n",
    "def env_creator(env_name):\n",
    "    if env_name == 'fishing-v1':\n",
    "        from gym_fishing.envs import FishingCtsEnv as env\n",
    "    elif env_name == \"conservation-v6\":\n",
    "        from gym_conservation.envs import NonStationaryV6 as env\n",
    "    elif env_name == \"fishing-v0\":\n",
    "        from gym_fishing.envs import FishingEnv as env\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use custom env creator instead of gym.make() to create callable env\n",
    "# Then register env with label in ray tune.\n",
    "env = env_creator('conservation-v6')\n",
    "tune.register_env('conservation-v6', lambda config: env())\n",
    "env1 = env_creator(\"fishing-v0\")\n",
    "tune.register_env('fishing-v0', lambda config: env1())\n",
    "env1 = env_creator(\"fishing-v1\")\n",
    "tune.register_env('fishing-v1', lambda config: env1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## minimal example\n",
    "#import gym, ray\n",
    "#from ray.rllib.agents.ppo import PPOTrainer\n",
    "#trainer = PPOTrainer(env=\"fishing-v1\", config={})\n",
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-27 23:37:47,879\tWARNING trainer.py:1948 -- You have specified 1 evaluation workers, but your `evaluation_interval` is None! Therefore, evaluation will not occur automatically with each call to `Trainer.train()`. Instead, you will have to call `Trainer.evaluate()` manually in order to trigger an evaluation run.\n",
      "2022-01-27 23:37:47,880\tWARNING ppo.py:151 -- `train_batch_size` (4000) cannot be achieved with your other settings (num_workers=6 num_envs_per_worker=1 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 666.\n",
      "2022-01-27 23:37:49,263\tWARNING services.py:1826 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67084288 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "\u001b[2m\u001b[36m(pid=1599095)\u001b[0m /home/cboettig/.local/share/virtualenvs/rl-ray-demo-y9hdSGSh/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "\u001b[2m\u001b[36m(pid=1599095)\u001b[0m   for external in metadata.entry_points().get(self.group, []):\n",
      "\u001b[2m\u001b[36m(pid=1599084)\u001b[0m /home/cboettig/.local/share/virtualenvs/rl-ray-demo-y9hdSGSh/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "\u001b[2m\u001b[36m(pid=1599084)\u001b[0m   for external in metadata.entry_points().get(self.group, []):\n",
      "\u001b[2m\u001b[36m(pid=1599076)\u001b[0m /home/cboettig/.local/share/virtualenvs/rl-ray-demo-y9hdSGSh/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "\u001b[2m\u001b[36m(pid=1599076)\u001b[0m   for external in metadata.entry_points().get(self.group, []):\n",
      "\u001b[2m\u001b[36m(pid=1599097)\u001b[0m /home/cboettig/.local/share/virtualenvs/rl-ray-demo-y9hdSGSh/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "\u001b[2m\u001b[36m(pid=1599097)\u001b[0m   for external in metadata.entry_points().get(self.group, []):\n",
      "\u001b[2m\u001b[36m(pid=1599089)\u001b[0m /home/cboettig/.local/share/virtualenvs/rl-ray-demo-y9hdSGSh/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "\u001b[2m\u001b[36m(pid=1599089)\u001b[0m   for external in metadata.entry_points().get(self.group, []):\n",
      "\u001b[2m\u001b[36m(pid=1599088)\u001b[0m /home/cboettig/.local/share/virtualenvs/rl-ray-demo-y9hdSGSh/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "\u001b[2m\u001b[36m(pid=1599088)\u001b[0m   for external in metadata.entry_points().get(self.group, []):\n",
      "2022-01-27 23:37:58,229\tWARNING deprecation.py:46 -- DeprecationWarning: `simple_optimizer` has been deprecated. This will raise an error in the future!\n",
      "2022-01-27 23:37:58,231\tWARNING trainer.py:1948 -- You have specified 1 evaluation workers, but your `evaluation_interval` is None! Therefore, evaluation will not occur automatically with each call to `Trainer.train()`. Instead, you will have to call `Trainer.evaluate()` manually in order to trigger an evaluation run.\n",
      "2022-01-27 23:37:58,232\tWARNING ppo.py:151 -- `train_batch_size` (4000) cannot be achieved with your other settings (num_workers=6 num_envs_per_worker=1 rollout_fragment_length=666)! Auto-adjusting `rollout_fragment_length` to 666.\n",
      "\u001b[2m\u001b[36m(pid=1599091)\u001b[0m /home/cboettig/.local/share/virtualenvs/rl-ray-demo-y9hdSGSh/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "\u001b[2m\u001b[36m(pid=1599091)\u001b[0m   for external in metadata.entry_points().get(self.group, []):\n",
      "2022-01-27 23:38:04,341\tINFO trainable.py:127 -- Trainable.setup took 16.463 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    }
   ],
   "source": [
    "# Configure the algorithm.\n",
    "config = {\n",
    "    # Environment (RLlib understands openAI gym registered strings).\n",
    "    \"env\": \"conservation-v6\",\n",
    "    # Use 2 environment workers (aka \"rollout workers\") that parallelly\n",
    "    # collect samples from their own environment clone(s).\n",
    "    \"num_workers\": 8,\n",
    "    # Change this to \"framework: torch\", if you are using PyTorch.\n",
    "    # Also, use \"framework: tf2\" for tf2.x eager execution.\n",
    "    \"framework\": \"torch\",\n",
    "    \"num_gpus\": 1,\n",
    "    # Tweak the default model provided automatically by RLlib,\n",
    "    # given the environment's observation- and action spaces.\n",
    "    \"model\": {\n",
    "         \"use_lstm\": True,\n",
    "#        \"fcnet_hiddens\": [128, 128],\n",
    "#        \"fcnet_activation\": \"relu\",\n",
    "    },\n",
    "    # Set up a separate evaluation worker set for the\n",
    "    # `trainer.evaluate()` call after training (see below).\n",
    "    \"evaluation_num_workers\": 1,\n",
    "    # Only for evaluation runs, render the env.\n",
    "    \"evaluation_config\": {\n",
    "        \"render_env\": False,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create our RLlib Trainer.\n",
    "trainer = impala.ImpalaTrainer(config=config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(500):\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'evaluation': {'episode_reward_max': 54.26525394784858,\n",
       "  'episode_reward_min': 39.04949102949177,\n",
       "  'episode_reward_mean': 47.02623127274943,\n",
       "  'episode_len_mean': 487.8,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 10,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [50.880918718155684,\n",
       "    45.3586469829504,\n",
       "    46.00949622415576,\n",
       "    47.330491343408504,\n",
       "    43.318821816283204,\n",
       "    51.78151185551697,\n",
       "    54.26525394784858,\n",
       "    50.00327623484258,\n",
       "    42.26440457484087,\n",
       "    39.04949102949177],\n",
       "   'episode_lengths': [476, 501, 501, 394, 501, 501, 501, 501, 501, 501]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.0947874866320623,\n",
       "   'mean_inference_ms': 1.01094974995539,\n",
       "   'mean_action_processing_ms': 0.10084617233198181,\n",
       "   'mean_env_wait_ms': 0.2282006399972098,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {}}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
